# 笔记

[toc]

## 爬虫基础

### http原理

http访问时，一般有get和post两种形式

post会提交表单，一般用于有数据提交的访问

请求头，其中比较重要的有Cookie，Referer，User-Agent（UA）

分别是服务器根据会话在本地储存的数据，访问来源（反爬虫），浏览器标识

各种各样的响应码，如：200正常，404没有找到页面等

### 网页结构

由html组成框架（有好多节点，每个节点有各自属性）

装载JavaScript进行各种动态交互

用CSS可以美化网页等

html文本中有title等各种节点，他们彼此有着父子兄弟子孙等十分复杂的关系

利用会话和cookie可以进行登录以及页面跳转记录保存等

通过设置代理可以隐藏IP地址和进行高频率爬取等

## 基本库

### Requests

requests常用代码，urllib没有深入学习太多。

```python
import requests
r = request.get('URL')# 基本爬取方法
print(r.status_code)# 状态码 
print(r.text)# 文本 
print(r.json)# json文本
print(r.cookies)# cookies信息
# 对于附带信息，可以这样：
data = { 
	'xxx': 'aa',
    'yyy': 'bb'
}
r = requests.get('', params=data)# 利用params参数
# 通过设置请求头，可伪装浏览器
headers = {
	'User-Agent': ''
    'Coookie': ''
}
r = requests.get('', headers=headers)# headers参数
# 抓取二进制数据
r = requests.get('这里是二进制数据的链接'）
with open('xxx.yy', 'wb ’) as f: # 进行文件的保存
	f.write(r.content) # 用.content可以查看二进制内容
# 文件上传方法
files = {'file': open ('xxx.yy', 'rb’)}
r = requests . post('', files=files)# 使用files 参数
```

## 解析库

### BeautifulSoup

先接触了BeautifulSoup，暂时没学XPath

```python
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, 'lxml')# 使用lxml进行格式化
print(soup.prettify())# 打印html的标准排版
print(soup.title
      soup.head
      soup.p)# 利用节点进行属性访问（只能访问第一个）
print(soup.title.string)# 使用string打印字符
print(soup.p.attrs['name']
      soup.p['name'])# 获取属性名，简便用法
print(soup.head.title.ul.li.a)# 只要属性是tag，就可以无限嵌套
print(soup.p.contents  # 直接子节点
      soup.p.children)# 获取所有子节点，包括文本和节点（生成器，可遍历）
print(soup.p.descendants)# 获取子孙节点（生成器）
print(soup.a.parent# 父节点
      soup.a.parents)# 所有祖先节点（生成器）
print(soup.a.next_sibling
      soup.a.previous_sibling)# 前后兄弟节点，（加s生成器）
# list(生成器)[]可以遍历
print(soup.find_all(name, attrs, recursive, text, **kwargs))
# 我最常用的家伙
# name:节点名, attrs={'name': 'xx'}或name='xx'都行(除了它要下划线class_)
print(soup.find_all(text=re.compile('xx')))
# 文字匹配，可用正则表达式，（import re）
# 找起东西来十分方便
```

## 保存文件

以csv保存：

```python
import csv
with open ('xxx.csv', 'w') as xx: # 写入，每次都会初始化文件
with open ('xxx.csv', 'a') as xx: # 加入，只会往后加
# 第一种，以列表形式加入
	writer = csv.writer(xx)
	writer.writerow(['a', 'b', '...', 'z'])
# 第二种，以字典形式加入
with open ('xxx.csv', 'w') as xx:
	fieldnames = ['a', 'b', '...', 'z']
	writer = csv.DictWriter(csvfile, fieldnames=fieldnames）
	writer.writeheader() 
	writer.writerow({'a':'xx', 'b':'xx', '...':'...', 'z':'xx'})
```

